<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>altriavin の blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="description" content="I am learning ML and DL by watching video on YouTube. There is my study notes. In the first lesson, he mainly introduce the concept of ML. And then, an example of linear models is given to help us open the door to ML.">
  
  
  
    <link rel="shortcut icon" href="../../../../altriavin.ico">
  
  
    
<link rel="stylesheet" href="../../../../fancybox/jquery.fancybox-1.3.4.css">

  
  
<link rel="stylesheet" href="../../../../css/style.css">

<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="../../../../index.html" id="logo">altriavin の blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="../../../../index.html" id="subtitle">student, friend, learning and life</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
      </nav>
      <nav id="sub-nav">
        
      </nav>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-LHY ML 1" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="" class="article-date">
  <time class="dt-published" datetime="2021-11-21T06:58:36.558Z" itemprop="datePublished">2021-11-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>I am learning ML and DL by watching video on YouTube. There is my study notes. In the first lesson, he mainly introduce the concept of ML. And then, an example of linear models is given to help us open the door to ML.</p>
<span id="more"></span>

<h3 id="The-type-of-ML"><a href="#The-type-of-ML" class="headerlink" title="The type of ML"></a>The type of ML</h3><p><strong>Regression</strong>: The function outputs a scalar.</p>
<p><strong>Classification</strong>: Given options(classes), the function outputs the correct one.</p>
<p><strong>structured learning</strong>: create something with structure</p>
<h3 id="The-example-of-Linear-model"><a href="#The-example-of-Linear-model" class="headerlink" title="The example of Linear model"></a>The example of Linear model</h3><p>a example for the Machine learning – predict the youtube channels</p>
<h4 id="Function-with-unknown"><a href="#Function-with-unknown" class="headerlink" title="Function with unknown"></a>Function with unknown</h4><p>$$<br>y = b + wx_1<br>$$</p>
<p>which $y$ represents the total views we will get today, $x_1$ is the number of views that we got on this channels yesterday, $w$ and $b$ is unknown parameters.</p>
<h4 id="Define-Loss-from-Training-Data"><a href="#Define-Loss-from-Training-Data" class="headerlink" title="Define Loss from Training Data"></a>Define Loss from Training Data</h4><p>Loss is a function on parameters $L(b,w)$</p>
<p>for example, we can define the loss function as follow:<br>$$<br>\widehat{y_i} = b_1 + w_1x_i<br>$$<br>$$<br>y_i = b_1 + w_1x_i<br>$$</p>
<p>$$<br>e_i = |{\widehat{y_i} - y_i}|<br>$$</p>
<p>$$<br>L = \frac{1}{N} \sum_{i=1}^{N}e_i<br>$$</p>
<p>which $\widehat{y_i}$ represent the $ith$ predictive value. $y_i$ is the $ith$ true value. $e_i$ is the the mean absolute error(MAE) of $\widehat{y_i}$ and $y_i$, in other case, we can define $e_i = (\widehat{y_i} - y_i)^2$, which is the mean square error(MSE). In that case, we use MAE. $Loss$ is the average of the $e_i$.</p>
<h4 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h4><p>$$<br>w^*, b^* = arg \min_{w,b}L<br>$$</p>
<p>which the $w^*$ and $b^*$ is the $w$ and $b$ which can make the loss smallest.</p>
<p>The way to find the best $w$ and $b$ is called <strong>Gradient Descent</strong>.</p>
<p>How to use the Gradient Descent? </p>
<p>Firstly, we suppose that there is only one paramenter $w$.  Then, we can get the error surface about $L$ and $w$ as follow.</p>
<p><img src="https://cdn.jsdelivr.net/gh/altriavin/PictureBed/img/the%20loss%20between%20L%20and%20w.jpeg"></p>
<center>fig 1: the loss between $L$ and $w$</center>

<p>After that, we need to randomly select an initial point called $w_0$ and compute the derivative of loss with respect to $w$ as follow:<br>$$<br>\frac{\partial{L}}{\partial{w}}|<em>{w=w^0}<br>$$<br>If the result is negative, we need to increase $w$, others, we need to decrease $w$. And the step size as follow:<br>$$<br>\eta \frac{\partial{L}}{\partial{w}}|</em>{w=w^0}<br>$$<br>which $\eta$ represent the learning rate, it depends on you. </p>
<p>The next step is to move to the new position which  is called $w_1$, the formula as follow:<br>$$<br>w_1 =<br>\begin{cases}<br>w_0 - \eta \frac{\partial{L}}{\partial{w}}|_{w=w^0} &amp; {\frac{\partial{L}}{\partial{w}} &gt;= 0}\<br>w_0 + \eta \frac{\partial{L}}{\partial{w}} &amp; {\frac{\partial{L}}{\partial{w}} &lt; 0}<br>\end{cases}<br>$$<br>After that, we need to update $w$ iteratively.</p>
<p><img src="https://cdn.jsdelivr.net/gh/altriavin/PictureBed/img/update%20the%20w%20iteratively.jpeg"></p>
<center>fig 2: update the w iteratively</center>

<p><strong>Gradient Descent</strong> is not a prefect method that has the problem of local minima.</p>
<p>Back to our problem, we actually have two parameters, $w$ and $b$. We can get the best $w$ and $b$  follow the steps below.</p>
<ol>
<li>(Randomly) Pick initial values $w^0$, $b^0$</li>
<li>compute</li>
</ol>
<p>$$<br>\frac{\partial L}{\partial w}|_{w=w^0,b=b_0}<br>$$</p>
<p>$$<br>\frac{\partial L}{\partial b}|_{w=w^0,b=b_0}<br>$$</p>
<p>and then, we can compute the $w_1$ and $b_1$ as the follow formula.<br>$$<br>w_1 = w_0 - \eta \frac{\partial L}{\partial w}|_{w=w^0,b=b^0}<br>$$</p>
<p>$$<br>b_1 = b_0 - \eta \frac{\partial L}{\partial b}|_{w=w^0,b=b^0}<br>$$</p>
<ol start="3">
<li>update $w$ and $b$ iteratively</li>
</ol>
<p>After the above step, we can get the error surface as follow.</p>
<p><img src="https://cdn.jsdelivr.net/gh/altriavin/PictureBed/img/the%20error%20surface%20of%20the%20w%20and%20b.jpeg"></p>
<center>fig 3: the error surface of the w and b</center>
      
    </div>
    <footer class="article-footer">
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="../../22/LHY%20ML%202/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          (no title)
        
      </div>
    </a>
  
  
    <a href="../../../02/08/to%20fo%20list/LHY%20ML%204/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">
        
          (no title)
        
      </div>
    </a>
  
</nav>

  
</article>


</section>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 altriavin<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a><br>
      <a target="_blank" rel="noopener" href="https://beian.miit.gov.cn">皖ICP备2021013786号</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
</nav>
    


<script src="../../../../js/jquery-1.4.3.min.js"></script>


  
<script src="../../../../fancybox/jquery.fancybox-1.3.4.js"></script>




<script src="../../../../js/script.js"></script>






<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>

  </div>
</body>
</html>